{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook run the experiment for double pendulum\n",
    "'''\n",
    "import gpflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from scipy.integrate import solve_ivp, odeint\n",
    "from gpflow.utilities import print_summary, positive, to_default_float, set_trainable\n",
    "from invariance_kernels import *\n",
    "from invariance_functions import *\n",
    "from invariance_kernels_2d import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "setup the problem, the x/v are in degrees\n",
    "'''\n",
    "mean = ZeroMean(4) \n",
    "\n",
    "time_step = 0.01\n",
    "training_time = 0.1\n",
    "testing_time = 1\n",
    "\n",
    "max_x = 60\n",
    "max_v = 10 \n",
    "n_train = 5\n",
    "train_starting_position1 = np.random.uniform(-max_x, max_x, (n_train))\n",
    "train_starting_position2 = np.random.uniform(-max_x, max_x, (n_train))\n",
    "train_starting_velocity1 = np.random.uniform(-max_v, max_v, (n_train))\n",
    "train_starting_velocity2 = np.random.uniform(-max_v, max_v, (n_train))\n",
    "\n",
    "print(train_starting_position1)\n",
    "print(train_starting_position2)\n",
    "print(train_starting_velocity1)\n",
    "print(train_starting_velocity2)\n",
    "\n",
    "data2 = get_double_pendulum_data(time_step, training_time, 1e-8, train_starting_position1, train_starting_position2, train_starting_velocity1, train_starting_velocity2) #switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scale the data\n",
    "'''\n",
    "scalerX = StandardScaler(with_mean=False, with_std=False).fit(data2[0])\n",
    "scalerY = StandardScaler(with_mean=False, with_std=False).fit(data2[1])\n",
    "#scalerX = StandardScaler().fit(data2[0])\n",
    "#scalerY = StandardScaler().fit(data2[1])\n",
    "#scalerX = MinMaxScaler((-1,1)).fit(data2[0])\n",
    "#scalerY = MinMaxScaler((-1,1)).fit(data2[1])\n",
    "X = scalerX.transform(data2[0])\n",
    "Y = scalerY.transform(data2[1])\n",
    "data = (X, Y)\n",
    "scalers = (scalerX, scalerY)\n",
    "time_setting = (testing_time, time_step)\n",
    "dynamics = (double_pendulum_dynamics1, double_pendulum_dynamics2)\n",
    "jitter = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fit the model\n",
    "'''\n",
    "print(\"moi\")\n",
    "moi = get_GPR_model_2D(get_MOI_2D(), mean, data, 100)\n",
    "print(moi.log_marginal_likelihood().numpy())\n",
    "#try:\n",
    "n_neighbours =  40\n",
    "print(\"known\")\n",
    "kernel_known = get_invariance_kernel_2D(DoublePendulumLocalInvariance, 1.5, 6, 0, 0.5, n_neighbours, jitter) #switch\n",
    "known = get_GPR_model_2D(kernel_known, mean, data, iterations=1000)\n",
    "print(known.log_marginal_likelihood().numpy())\n",
    "\n",
    "polynomial_degree = 3\n",
    "print(\"learnt\")\n",
    "\n",
    "kernel = get_paramertised_invariance_kernel_2D(PolynomialLocalInvariance2D, 1.5, 6, 0, 0.5, n_neighbours, jitter, polynomial_degree) \n",
    "model = get_GPR_model_2D(kernel, mean, data, iterations=10000, old_model=known)\n",
    "print(model.log_marginal_likelihood().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "evaluate performace\n",
    "'''\n",
    "eva_future_moi = []\n",
    "eva_future_known = []\n",
    "eva_future_learnt = []\n",
    "\n",
    "def energy(X):\n",
    "    return -2*np.cos(X[:,0])-np.cos(X[:,1])+0.5*tf.square(X[:,2])+0.5*(tf.square(X[:,2])+tf.square(X[:,3])+2*X[:,2]*X[:,3]*np.cos(X[:,0]-X[:,1]))\n",
    "lml_moi = moi.log_marginal_likelihood().numpy()\n",
    "lml_inv = known.log_marginal_likelihood().numpy()\n",
    "lml_inv_p = model.log_marginal_likelihood().numpy()\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    test_starting_position1 = np.radians(np.random.uniform(-max_x, max_x))\n",
    "    test_starting_position2 = np.radians(np.random.uniform(-max_x, max_x))\n",
    "    test_starting_velocity1 = np.radians(np.random.uniform(-max_v, max_v))\n",
    "    test_starting_velocity2 = np.radians(np.random.uniform(-max_v, max_v))\n",
    "    test_starting = (test_starting_position1, test_starting_position2, test_starting_velocity1, test_starting_velocity2)\n",
    "#    print(test_starting)\n",
    "    evaluate_moi = evaluate_model_future_2D(moi, test_starting, dynamics, time_setting, scalers, energy)\n",
    "    eva_future_moi.append(evaluate_moi[0])\n",
    "    print(evaluate_moi[0])\n",
    "    evaluate_known = evaluate_model_future_2D(known, test_starting, dynamics, time_setting, scalers, energy)\n",
    "    eva_future_known.append(evaluate_known[0])\n",
    "    print(evaluate_known[0])\n",
    "    evaluate_learnt = evaluate_model_future_2D(model, test_starting, dynamics, time_setting, scalers, energy)\n",
    "    eva_future_learnt.append(evaluate_learnt[0])\n",
    "    print(evaluate_learnt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "metrics\n",
    "'''\n",
    "print(\"Log Marginal Likelihood & \" + format((lml_moi),\".2f\")+\" & \"+ format((lml_inv),\".2f\") + \" & \"+ format((lml_inv_p),\".2f\") + \" & \"+' \\\\\\\\')\n",
    "print(\"MSE & \"+ format((np.mean(eva_future_moi)),\".4f\")+\" & \"+format(np.mean(eva_future_known),\".4f\")+\" & \"+format((np.mean(eva_future_learnt)),\".4f\")+ ' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot a predicted trajectory\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "t = np.linspace(0, testing_time, int(testing_time/time_step))\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs[0][0].plot(t,evaluate_known[4][:,0],label=\"truth\", color=\"black\")\n",
    "axs[0][0].plot(t,evaluate_moi[1][:,0], \"--\", label=\"RBF\", color=\"red\")\n",
    "axs[0][0].plot(t,evaluate_known[1][:,0], \"--\", label=\"known\", color=\"blue\")\n",
    "axs[0][0].plot(t,evaluate_learnt[1][:,0], \"--\", label=\"learnt\", color=\"green\")\n",
    "axs[0][0].set_title(\"q_1\")\n",
    "axs[0][0].set_xlabel(\"t\")\n",
    "axs[0][0].legend()\n",
    "\n",
    "axs[0][1].plot(t,evaluate_known[4][:,1],label=\"truth\", color=\"black\")\n",
    "axs[0][1].plot(t,evaluate_moi[1][:,1], \"--\", label=\"RBF\", color=\"red\")\n",
    "axs[0][1].plot(t,evaluate_known[1][:,1], \"--\", label=\"known\", color=\"blue\")\n",
    "axs[0][1].plot(t,evaluate_learnt[1][:,1], \"--\", label=\"learnt\", color=\"green\")\n",
    "axs[0][1].set_title(\"q_2\")\n",
    "axs[0][1].set_xlabel(\"t\")\n",
    "axs[0][1].legend()\n",
    "\n",
    "axs[1][0].plot(t,evaluate_known[4][:,2],label=\"truth\", color=\"black\")\n",
    "axs[1][0].plot(t,evaluate_moi[1][:,2], \"--\", label=\"RBF\", color=\"red\")\n",
    "axs[1][0].plot(t,evaluate_known[1][:,2], \"--\", label=\"known\", color=\"blue\")\n",
    "axs[1][0].plot(t,evaluate_learnt[1][:,2], \"--\", label=\"learnt\", color=\"green\")\n",
    "axs[1][0].set_title(\"p_1\")\n",
    "axs[1][0].set_xlabel(\"t\")\n",
    "axs[1][0].legend()\n",
    "\n",
    "axs[1][1].plot(t,evaluate_known[4][:,3],label=\"truth\", color=\"black\")\n",
    "axs[1][1].plot(t,evaluate_moi[1][:,3], \"--\", label=\"RBF\", color=\"red\")\n",
    "axs[1][1].plot(t,evaluate_known[1][:,3], \"--\", label=\"known\", color=\"blue\")\n",
    "axs[1][1].plot(t,evaluate_learnt[1][:,3], \"--\", label=\"learnt\", color=\"green\")\n",
    "axs[1][1].set_title(\"p_2\")\n",
    "axs[1][1].set_xlabel(\"t\")\n",
    "axs[1][1].legend()\n",
    "\n",
    "plt.subplots_adjust(left=0.2,\n",
    "                    bottom=0.2, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"figures/double_pendulum_predicted.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot the energy\n",
    "'''\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(t, evaluate_learnt[5], \"--\",label=\"true\", color=\"black\")\n",
    "plt.plot(t, evaluate_moi[6], \"--\",label=\"RBF\", color=\"red\")\n",
    "plt.plot(t, evaluate_known[6], \"--\",label=\"known\", color=\"blue\")\n",
    "plt.plot(t, evaluate_learnt[6], \"--\",label=\"learnt\", color=\"green\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"E\")\n",
    "#plt.savefig(\"figures/double_pendulum_energy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "evaluate whether the model regonise the true invariance when we initialise the polynomialat theoretically correct value\n",
    "by compute the MSE for theortically correct polynomial, fully optimised polynomial and random polynomial (50)\n",
    "'''\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "def energy(X):\n",
    "    return -2*np.cos(X[:,0])-np.cos(X[:,1])+0.5*tf.square(X[:,2])+0.5*(tf.square(X[:,2])+tf.square(X[:,3])+2*X[:,2]*X[:,3]*np.cos(X[:,0]-X[:,1]))\n",
    "\n",
    "n_neighbours = 40\n",
    "\n",
    "\n",
    "kernel = get_paramertised_invariance_kernel_2D(PolynomialLocalInvariance2D, 1.5, 6, 0, 0.5, n_neighbours, jitter, polynomial_degree) \n",
    "model_fixed = get_GPR_model_2D(kernel, mean, data, iterations=1000, old_model=known, fixed=True)\n",
    "\n",
    "print(model_fixed.log_marginal_likelihood().numpy())\n",
    "\n",
    "\n",
    "polynomial_degree = 3\n",
    "print(\"learnt\")\n",
    "test_starting_position1 = np.radians(np.random.uniform(-max_x, max_x))\n",
    "test_starting_position2 = np.radians(np.random.uniform(-max_x, max_x))\n",
    "test_starting_velocity1 = np.radians(np.random.uniform(-max_v, max_v))\n",
    "test_starting_velocity2 = np.radians(np.random.uniform(-max_v, max_v))\n",
    "test_starting = (test_starting_position1, test_starting_position2, test_starting_velocity1, test_starting_velocity2)\n",
    "\n",
    "evaluate_moi = evaluate_model_future_2D(moi, test_starting, dynamics, time_setting, scalers, energy)\n",
    "print(evaluate_moi[0])\n",
    "evaluate_known = evaluate_model_future_2D(known, test_starting, dynamics, time_setting, scalers, energy)\n",
    "print(evaluate_known[0])\n",
    "\n",
    "evaluate_learnt_fixed = evaluate_model_future_2D(model_fixed, test_starting, dynamics, time_setting, scalers, energy)\n",
    "print(evaluate_learnt_fixed[0])\n",
    "\n",
    "evaluate_learnt_free = evaluate_model_future_2D(model, test_starting, dynamics, time_setting, scalers, energy)\n",
    "print(evaluate_learnt_free[0])\n",
    "\n",
    "\n",
    "grids_lml = []\n",
    "grids_eva = []\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    kernel_grid = get_paramertised_invariance_kernel_2D(PolynomialLocalInvariance2D, 1.5, 6, 0, 0.5, n_neighbours, jitter, polynomial_degree) \n",
    "    kernel_grid.poly = gpflow.Parameter(0.1*np.random.normal(size=kernel_grid.poly.shape), transform =tfp.bijectors.Sigmoid(to_default_float(-1.), to_default_float(1.)), trainable=False, prior=tfp.distributions.Laplace(to_default_float(0),(0.1)), name=\"poly\")\n",
    "    model_grid = get_GPR_model_2D(kernel_grid, mean, data, iterations=1000, old_model=known, fixed=True)\n",
    "    print(model_grid.log_marginal_likelihood().numpy())\n",
    "\n",
    "    evaluate_learnt_grid = evaluate_model_future_2D(model_grid, test_starting, dynamics, time_setting, scalers, energy)\n",
    "    print(evaluate_learnt_grid[0])\n",
    "    grids_eva.append(evaluate_learnt_grid[0])\n",
    "    grids_lml.append(model_grid.log_marginal_likelihood().numpy())\n",
    "    if i>=2:\n",
    "        print(pearsonr(grids_lml, grids_eva))\n",
    "        print(spearmanr(grids_lml, grids_eva))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(grids_lml, grids_eva, s=10, label=\"randomly initialised polynomial\")\n",
    "plt.scatter(model_fixed.log_marginal_likelihood().numpy(), evaluate_learnt_fixed[0],marker=\"X\",s=10, color=\"red\", label=\"theoretically initialised polynomial\", alpha=0.5)\n",
    "plt.scatter(model.log_marginal_likelihood().numpy(), evaluate_learnt_free[0], s=10, color=\"green\", label=\"optimised\", alpha=0.5)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"log marginal likelihood\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.savefig(\"figures/double_pendulum_polynomial.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "print(spearmanr(grids_lml, (grids_eva)))\n",
    "print(pearsonr(grids_lml, (grids_eva)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(grids_eva)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55ee67ca95ee8f2aeaeec8596b5a6d7efa8132a3ef6eb56881e1057cc4b5139b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
