{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from scipy.integrate import solve_ivp, odeint\n",
    "from gpflow.utilities import print_summary, positive, to_default_float, set_trainable\n",
    "from invariance_kernels import zero_mean, get_MOI, get_MOI2D, get_Pendulum_Invariance, get_SHM_Invariance, get_SHM2D_Invariance, get_Double_Pendulum_Invariance\n",
    "from invariance_functions import degree_of_freedom, get_GPR_2Dmodel, get_SHM2D_data, evaluate_2Dmodel, get_double_pendulum_data, get_GPR_2Dmodel_sparse\n",
    "from local_invariance_kernels import  get_Polynomial_2D_Local_Invariance\n",
    "from parameterised_invariance_kernels import get_Polynomial_2D_Invariance, get_Polynomial_2D_Invariance_fixed\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "mean = zero_mean(4)\n",
    "\n",
    "time_step = 0.01\n",
    "training_time = 0.1\n",
    "testing_time = 0.1\n",
    "\n",
    "max_x = 5\n",
    "n_train = 4\n",
    "train_starting_position1 = np.random.uniform(-max_x, max_x, (n_train))\n",
    "train_starting_position2 = np.random.uniform(-max_x, max_x, (n_train))\n",
    "train_starting_velocity1 = np.random.uniform(-max_x/5, max_x/5, (n_train))\n",
    "train_starting_velocity2 = np.random.uniform(-max_x/5, max_x/5, (n_train))\n",
    "test_starting_position1 = np.random.uniform(-max_x, max_x)\n",
    "test_starting_position2 = np.random.uniform(-max_x, max_x)\n",
    "test_starting_velocity1 = np.random.uniform(-max_x/5, max_x/5)\n",
    "test_starting_velocity2 = np.random.uniform(-max_x/5, max_x/5)\n",
    "\n",
    "print(train_starting_position1)\n",
    "print(train_starting_position2)\n",
    "print(train_starting_velocity1)\n",
    "print(train_starting_velocity2)\n",
    "\n",
    "print(test_starting_position1)\n",
    "print(test_starting_position2)\n",
    "print(test_starting_velocity1)\n",
    "print(test_starting_velocity2)\n",
    "\n",
    "data = get_SHM2D_data(time_step, training_time, 1e-8, train_starting_position1, train_starting_position2, train_starting_velocity1, train_starting_velocity2) #switch\n",
    "test_data = get_SHM2D_data(time_step, testing_time, 1e-8,[test_starting_position1],[test_starting_position2],[test_starting_velocity1],[test_starting_velocity2] )\n",
    "for jitter in [1e-5]:\n",
    "    moi = get_GPR_2Dmodel(get_MOI2D(), mean, data, \"scipy\", 1000, 0.1)\n",
    "    print(\"%s, \"%round(moi.log_marginal_likelihood().numpy()))\n",
    "    evaluate_moi = evaluate_2Dmodel(moi, test_data, time_step)\n",
    "    print(evaluate_moi[:2])\n",
    "    for invar_density in [6]: #np.arange(10, 30, 10):\n",
    "            try:\n",
    "                print(\"SHM\")\n",
    "                kernel = get_SHM2D_Invariance(5, invar_density, jitter) #switch\n",
    "                m = get_GPR_2Dmodel(kernel, mean, data, \"scipy\", iterations=1000, lr=0.1)\n",
    "                print(round(m.log_marginal_likelihood().numpy()))\n",
    "                evaluate_invariance = evaluate_2Dmodel(m, test_data, time_step)\n",
    "                print(evaluate_invariance[:2])\n",
    "                polynomial_degree = 1\n",
    "                print(\"polynomial\")\n",
    "                kernel = get_Polynomial_2D_Local_Invariance(5, 30, jitter, [polynomial_degree,polynomial_degree,polynomial_degree,polynomial_degree]) #switch\n",
    "#                kernel = get_Polynomial_2D_Invariance(3, invar_density, jitter, [polynomial_degree,polynomial_degree,polynomial_degree,polynomial_degree]) #switch\n",
    "                m, best = get_GPR_2Dmodel_sparse(kernel, mean, data, \"adam\", iterations=20000, lr=0.001, reg=1, drop_rate=0)\n",
    "                print(round(m.log_marginal_likelihood().numpy()))\n",
    "                evaluate_invariance = evaluate_2Dmodel(m, test_data, time_step)\n",
    "                print(evaluate_invariance[:2])\n",
    "                print(kernel.f1_poly)\n",
    "                print(kernel.f2_poly)\n",
    "                print(kernel.g1_poly)\n",
    "                print(kernel.g2_poly)\n",
    "\n",
    "            except tf.errors.InvalidArgumentError:\n",
    "                print(\"jitter too small\")\n",
    "                break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(moi.likelihood.variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "t = np.linspace(0, testing_time, int(testing_time/time_step))[1:-1]\n",
    "fig, axs = plt.subplots(4)\n",
    "axs[0].plot(t,evaluate_moi[2][:,0])\n",
    "axs[0].fill_between(t,evaluate_moi[2][:,0]+1.96*np.sqrt(evaluate_moi[3][:,0]+moi.likelihood.variance.numpy()),evaluate_moi[2][:,0]-1.96*np.sqrt(evaluate_moi[3][:,0]+moi.likelihood.variance.numpy()), color=\"grey\")\n",
    "axs[0].plot(t, test_data[0][:,0],'--')\n",
    "axs[1].plot(t,evaluate_moi[2][:,1])\n",
    "axs[1].fill_between(t,evaluate_moi[2][:,1]+1.96*np.sqrt(evaluate_moi[3][:,1]+moi.likelihood.variance.numpy()),evaluate_moi[2][:,1]-1.96*np.sqrt(evaluate_moi[3][:,1]+moi.likelihood.variance.numpy()), color=\"grey\")\n",
    "axs[1].plot(t, test_data[0][:,1],'--')\n",
    "axs[2].plot(t,evaluate_moi[2][:,2])\n",
    "axs[2].fill_between(t,evaluate_moi[2][:,2]+1.96*np.sqrt(evaluate_moi[3][:,2]+moi.likelihood.variance.numpy()),evaluate_moi[2][:,2]-1.96*np.sqrt(evaluate_moi[3][:,2]+moi.likelihood.variance.numpy()), color=\"grey\")\n",
    "axs[2].plot(t, test_data[0][:,2],'--')\n",
    "axs[3].plot(t,evaluate_moi[2][:,3])\n",
    "axs[3].fill_between(t,evaluate_moi[2][:,3]+1.96*np.sqrt(evaluate_moi[3][:,3]+moi.likelihood.variance.numpy()),evaluate_moi[2][:,3]-1.96*np.sqrt(evaluate_moi[3][:,3]+moi.likelihood.variance.numpy()), color=\"grey\")\n",
    "axs[3].plot(t, test_data[0][:,3],'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(4)\n",
    "axs[0].plot(t,evaluate_invariance[2][:,0])\n",
    "axs[0].fill_between(t,evaluate_invariance[2][:,0]+1.96*np.sqrt(evaluate_invariance[3][:,0]+m.likelihood.variance.numpy()),evaluate_invariance[2][:,0]-1.96*np.sqrt(evaluate_invariance[3][:,0]+m.likelihood.variance.numpy()), color=\"grey\")\n",
    "axs[0].plot(t, test_data[0][:,0],'--')\n",
    "axs[1].plot(t,evaluate_invariance[2][:,1])\n",
    "axs[1].fill_between(t,evaluate_invariance[2][:,1]+1.96*np.sqrt(evaluate_invariance[3][:,1]+m.likelihood.variance.numpy()),evaluate_invariance[2][:,1]-1.96*np.sqrt(evaluate_invariance[3][:,1]+m.likelihood.variance.numpy()), color=\"grey\")\n",
    "axs[1].plot(t, test_data[0][:,1],'--')\n",
    "axs[2].plot(t,evaluate_invariance[2][:,2])\n",
    "axs[2].fill_between(t,evaluate_invariance[2][:,2]+1.96*np.sqrt(evaluate_invariance[3][:,2]+m.likelihood.variance.numpy()),evaluate_invariance[2][:,2]-1.96*np.sqrt(evaluate_invariance[3][:,2]+m.likelihood.variance.numpy()), color=\"grey\")\n",
    "axs[2].plot(t, test_data[0][:,2],'--')\n",
    "axs[3].plot(t,evaluate_invariance[2][:,3])\n",
    "axs[3].fill_between(t,evaluate_invariance[2][:,3]+1.96*np.sqrt(evaluate_invariance[3][:,3]+m.likelihood.variance.numpy()),evaluate_invariance[2][:,3]-1.96*np.sqrt(evaluate_invariance[3][:,3]+m.likelihood.variance.numpy()), color=\"grey\")\n",
    "axs[3].plot(t, test_data[0][:,3],'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
